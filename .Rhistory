all <- ncvar_get(nc_all, 'pr', start=c(1,1), count = c(-1,-1))
## Preprocessing to extract 50 ensemble members available for full 1960-2013 period
avail <- c(1:10, 36:50, 61:70, 86:100)
startYear <- 1960
endYear <- 2013
fullYears <- startYear:endYear
nYears <- length(fullYears)
baseline <- 1961:2010
baseIndices <- baseline - startYear + 1
## 54 years (rows) with 50 ensemble members (columns)
all <- all[ , avail]
## Calculate (relative) precipitation anomalies
mn <- mean(all[baseIndices, ])
allAnom <- all / mn
## Set up replicated data in format required
nReplicates <- ncol(allAnom)         # 50 replicates (ensemble members)
threshold <- quantile(allAnom, .02)   # 2th percentile of distribution
allAnomVec <- c(allAnom)  ## string out data in a column-wise vector
blockIndex <- rep(fullYears, nReplicates)
replicateIndex <- rep(1:nReplicates, each = nYears)
sub <- which(allAnomVec < threshold)
allAnomVec[1:20]
blockIndex[1:20]
replicateIndex[1:20]
hist(allAnomVec[sub])
blockIndex[sub]
replicateIndex[sub]
out <- fit_pot(allAnomVec[sub], threshold = threshold,
x = data.frame(years = fullYears), locationFun = ~years,
nBlocks = nYears, blockIndex = blockIndex[sub], firstBlock = startYear,
replicateIndex = replicateIndex[sub], nReplicates = nReplicates,
returnPeriod = 20, returnValue = 0.6,
xNew = data.frame(years = endYear),
xContrast = data.frame(years = startYear),
upperTail = FALSE)
## Note: linear model for location parameter
## Note: 'replicateIndex' and 'nReplicates' allow for correct handling of model ensembles
## Note: 'upperTail = FALSE' for analysis of lower tail extremes
out$returnValue           ## 20-year return value for 2013
exp(out$logReturnPeriod)   ## Return period for 2013 for anomaly of 60% average precipitation
exp(out$logReturnPeriod + c(-2, 2) * out$se_logReturnPeriod)
exp(out$logReturnProbDiff)  ## Ratio of return probabilities for end year compared to begin year
exp(out$logReturnProbDiff + c(-2, 2) * out$se_logReturnProbDiff)  ## confidence interval
```
Note that with an ensemble we have the statistical power to estimate probabilities of fairly extreme events at the seasonal/annual time scale.
# Event attribution: 2011 Texas heatwave/drought using binomial counting
Now consider an event attribution study, using an ensemble of model simulations only for 2011, to try to understand the 2011 Texas heatwave/drought.
Instead of doing EVA (which requires the event be extreme in both factual and counterfactual),
simply count the number of exceedances and use epidemiological/biostatistical
methods for estating risk ratios (borrowed from analysis of biomedical experiments).
```{r, fig.cap=""}
nc_all <- nc_open('pr_MarAug_LBNL_CAM5-1-1degree_All-Hist_est1_v2-0_196001-201312.nc')
nc_nat <- nc_open('pr_MarAug_LBNL_CAM5-1-1degree_Nat-Hist_CMIP5-est1_v2-0_196001-201312.nc')
all <- ncvar_get(nc_all, 'pr', start=c(1,1), count = c(-1,-1))
nat <- ncvar_get(nc_nat, 'pr', start=c(1,1), count = c(-1,-1))
avail <- c(1:10, 36:50, 61:70, 86:100)
startYr = 1960
endYr = 2013
fullYrs = startYr:endYr
baseline = 1961:2010
baseIndices <- baseline - startYr + 1
## Calculate anomalies based on baseline period, 50 member full ensemble
mnModel = mean(all[baseIndices, avail])
allAnom = all / mnModel
natAnom = nat / mnModel  # relative to all forcings baseline
eventYear <-  52 # 2011
level <- 0.9  # 90% confidence intervals
## Restrict to 2011
allAnom <- allAnom[eventYear, ]
natAnom <- natAnom[eventYear, ]
## Actual event of 0.4 (40% normal precipitation) has no exceedances
## in either scenario, so use slightly less extreme definition
event <- 0.5
yA <- sum(allAnom < event)
yN <- sum(natAnom < event)
n <- length(allAnom)
print(yA)  # factual events
print(yN)  # counterfactual events
print(n)   # sample size (# ensemble members)
result <- calc_riskRatio_binom(y = c(yA, yN), n = rep(n, 2),
ciType = c('koopman', 'lrt'),
ciLevel = level, lrtControl = list(bounds = c(0.01, 500)))
result$riskRatio
result$ci_riskRatio_lrt  ## likelihood-ratio based interval
result$ci_riskRatio_koopman  ## Koopman-based interval
## Consider even less extreme event of 0.6
event <- 0.6
yA <- sum(allAnom < event)
yN <- sum(natAnom < event)
n <- length(allAnom)
print(yA)  # factual events
print(yN)  # counterfactual events
print(n)   # sample size (# ensemble members)
result <- calc_riskRatio_binom(y = c(yA, yN), n = rep(n, 2),
ciType = c('koopman', 'lrt'),
ciLevel = level, lrtControl = list(bounds = c(0.01, 500)))
result$riskRatio
result$ci_riskRatio_lrt  ## likelihood-ratio based interval
result$ci_riskRatio_koopman  ## Koopman-based interval
```
# Event attribution: 2011 Texas heatwave/drought using EVA
We can also use extreme value analysis to calculate the risk ratio, if the event is extreme in both scenarios.
I just found a bug (to be fixed in the next version of climextRemes) when using the likelihood-ratio-based interval with the lower-tail extreme, so we need to pull in the fixed version of the function.
```{r, fig.cap=""}
source('calc_riskRatio_pot_fixed.R')
```
Now let's proceed
```{r, fig.cap=""}
thrAll <- quantile(allAnom, 0.1)
thrNat <- quantile(natAnom, 0.1)
y1 <- allAnom[allAnom < thrAll]
y2 <- natAnom[natAnom < thrNat]
result <- calc_riskRatio_pot(0.4, y1 = allAnom[allAnom < thrAll], y2 = natAnom[natAnom < thrNat],
threshold1 = thrAll, threshold2 = thrNat,
nBlocks1 = 1, nBlocks2 = 1,
upperTail = FALSE,
ciType = c('delta'))
result$ci_riskRatio_delta
```
setwd("/Users/megancattau 1/Dropbox/0_EarthLab/US_Pyromes")#
setwd("anthro_ign_code/")#
#
# Projection for layers#
#EPSG:32613#
data_crs<- " +proj=utm +zone=13 +datum=WGS84 +units=m +no_defs +ellps=WGS84 "#
#
library(sf)#
library(raster)#
library(rgdal)#
library(tidyr)#
library(plyr)#
library(dplyr)#
library(ggplot2)#
library(segmented)#
library(ggthemes)#
library(ggmap)#
library(RColorBrewer)#
library(ggpubr)#
#
#########################################################################
##################### TABLE OF CONTENTS ##########################
#########################################################################
# 0. Import data and sample ecoregion (level 1)#
# 1. Characterizing ignitions#
# 2. Temporal trends#
# 3. Characterizing fire~ign#
# 4. Characterizing fire~ign/time#
# 5. Characterizing fire~ign_ecoregion#
# 6. Characterizing fire~ign_ecoregion/time#
# 7. Segmentation - Relationship between anthropogenic ignitions and fire physical characteristics#
# 8. Human fires are smaller and less intense... because of season length and freq?#
#########################################################################
######################### 0. Import data  and plot it #############################
#########################################################################
#
# Import data#
#
# Fire variables sampled at 50km resolution - created with code "1. Anthro_sample_data", also in Github repo#
samples_df<-read.csv("samples_df.csv")#
names(samples_df)#
samples_df<-samples_df[,-1]	#
#
samples_spatial<-samples_df#
coordinates(samples_spatial)<-~x+y#
proj4string(samples_spatial)<-CRS("+init=epsg:32613")
## Import overlay - EPA Level 1 Ecoregions clipped to States, in Github repo#
Ecoregion <- st_read(dsn = 'Ecoregion_state', layer = "Eco_L1_pclp", quiet = TRUE) %>%#
  st_transform(., data_crs)#
Ecoregion2<-as(Ecoregion, 'Spatial')#
#
overlay <- fortify(Ecoregion2, region="NA_L1NAME")#
#
# all the mean values plus FID and ecoregion#
samples_df_mean<-samples_df[,c(1:15, 376, 379)]#
samples_spatial_mean<-samples_spatial[,c(1:15, 376, 377)]#
# Names to pass later to functions#
names_vector<-c("Fire frequency (MODIS)", "Fire frequency  (MTBS)", "Fire frequency  (FPA FOD)", "Mean Intensity (MODIS)", "Maximum Intensity (MODIS)", "Mean Fire Size (MTBS)", "Max Fire Size (MTBS)",  "Mean Fire Size (FPA FOD)", "Max Fire Size (FPA FOD)",  "Burned Area (MTBS)",  "Burned Area (FPA FOD)", "Season Length (MTBS)",  "Season Length (MODIS)",  "Season Length (FPA FOD)", "Prop human ign (FPA FOD)")#
#
names_simple<-c("Fire Frequency (n fires)", "Fire Frequency (n fires)", "Fire Frequency (n fires)", "Average Intensity (MW)", "Extreme Intensity(MW)", "Average Fire Size (ha)", "Extreme Fire Size (ha)", "Average Fire Size (ha)", "Extreme Fire Size (ha)", "Burned area (ha)", "Burned area (ha)", "Season Length (days)","Season Length (days)", "Season Length (days)", "Human Ignitions (Proportion)")#
#
names_no_units<-c("Fire Frequency", "Fire Frequency", "Fire Frequency", "Average Intensity", "Extreme Intensity", "Average Fire Size", "Extreme Fire Size", "Average Fire Size", "Extreme Fire Size", "Burned area", "Burned area", "Season Length","Season Length", "Season Length", "Human Ignitions")#
#
units_simple<-c("n fires", "n fires", "n fires", "MW", "MW", "ha", "ha", "ha","ha", "ha", "ha", "days","days", "days", "prop")
samples_df$anthro<-ifelse(samples_df$Perc_human_Short_mean>=0.75, 1, #
                          ifelse(samples_df$Perc_human_Short_mean<=0.25, 2, #
                          0))#
#
samples_df$ign<-ifelse(samples_df$anthro==1, "Human", ifelse(samples_df$anthro==2, "Lightning", -9999))
samples_df_annual<-samples_df[,c(16:375, 376:379, 381)]#
#
samples_df_long<-gather(samples_df_annual, key=variable, value=value, -FID, -ign, -x, -y, -ecoregion)#
#
# add year column#
extractYear <- function(x, n){#
  substr(x, nchar(x)-n+1, nchar(x))#
}#
samples_df_long$year1<-extractYear(samples_df_long$variable, 4)#
samples_df_long$year<-as.numeric(samples_df_long$year1)#
unique(samples_df_long$variable)#
unique(samples_df_long$year)#
#
samples_df_long$ecoregion<-as.factor(samples_df_long$ecoregion)#
samples_df_long$ign<-as.factor(samples_df_long$ign)
library(stringr)#
samples_df$ecoregion2<-str_to_title(samples_df$ecoregion)
mean_annual_value_by_eco<-function(title){#
  value_by_group<-title %>% #
    group_by(ign, ecoregion, time) %>% #
    summarise(#
      count = n(),#
      value_by_group = mean(value, na.rm = TRUE)#
    )#
  value_by_group#
}#
#
# pass this list to function above #
grouped_list_eco=vector("list", 15)#
for (i in 1:15){#
  grouped_list_eco[[i]]<-mean_annual_value_by_eco(fire_chars[[i]])#
}
# grab FID, x, y, ecoregion, and ign#
samples_df_annual<-samples_df[,c(16:375, 376:379, 381)]#
#
samples_df_long<-gather(samples_df_annual, key=variable, value=value, -FID, -ign, -x, -y, -ecoregion)#
#
# add year column#
extractYear <- function(x, n){#
  substr(x, nchar(x)-n+1, nchar(x))#
}#
samples_df_long$year1<-extractYear(samples_df_long$variable, 4)#
samples_df_long$year<-as.numeric(samples_df_long$year1)#
unique(samples_df_long$variable)#
unique(samples_df_long$year)#
#
samples_df_long$ecoregion<-as.factor(samples_df_long$ecoregion)#
samples_df_long$ign<-as.factor(samples_df_long$ign)#
#
# group each fire variables together#
#
MODIS_numfires<-samples_df_long[grep("MODIS_Numfires_", samples_df_long$variable),]#
MODIS_numfires$time<-MODIS_numfires$year - min(MODIS_numfires$year)#
#
MTBS_numfires<-samples_df_long[grep("MTBS_Numfires_", samples_df_long$variable),]#
MTBS_numfires$time<-MTBS_numfires$year - min(MTBS_numfires$year)#
#
Short_numfires<-samples_df_long[grep("Short_Numfires_", samples_df_long$variable),]#
Short_numfires$time<-Short_numfires$year - min(Short_numfires$year)#
#
MODIS_meanFRP<-samples_df_long[grep("MODIS_meanFRP_", samples_df_long$variable),]#
MODIS_meanFRP$time<-MODIS_meanFRP$year - min(MODIS_meanFRP$year)#
#
MODIS_maxFRP<-samples_df_long[grep("MODIS_maxFRP_", samples_df_long$variable),]#
MODIS_maxFRP$time<-MODIS_maxFRP$year - min(MODIS_maxFRP$year)#
#
MTBS_meanArea<-samples_df_long[grep("MTBS_meanArea_", samples_df_long$variable),]#
MTBS_meanArea$time<-MTBS_meanArea$year - min(MTBS_meanArea$year)#
#
MTBS_maxArea<-samples_df_long[grep("MTBS_maxArea_", samples_df_long$variable),]#
MTBS_maxArea$time<-MTBS_maxArea$year - min(MTBS_maxArea$year)#
#
Short_meanArea<-samples_df_long[grep("Short_meanArea_", samples_df_long$variable),]#
Short_meanArea$time<-Short_meanArea$year - min(Short_meanArea$year)#
#
Short_maxArea<-samples_df_long[grep("Short_maxArea_", samples_df_long$variable),]#
Short_maxArea$time<-Short_maxArea$year - min(Short_maxArea$year)#
#
MTBS_sumArea<-samples_df_long[grep("MTBS_sumArea_", samples_df_long$variable),]#
MTBS_sumArea$time<-MTBS_sumArea$year - min(MTBS_sumArea$year)#
#
Short_sumArea<-samples_df_long[grep("Short_sumArea_", samples_df_long$variable),]#
Short_sumArea$time<-Short_sumArea$year - min(Short_sumArea$year)#
#
MTBS_stdJD<-samples_df_long[grep("MTBS_stdJD_", samples_df_long$variable),]#
MTBS_stdJD$time<-MTBS_stdJD$year - min(MTBS_stdJD$year)#
#
MODIS_stdJD<-samples_df_long[grep("MODIS_stdJD_", samples_df_long$variable),]#
MODIS_stdJD$time<-MODIS_stdJD$year - min(MODIS_stdJD$year)#
#
Short_stdJD<-samples_df_long[grep("Short_stdJD_", samples_df_long$variable),]#
Short_stdJD$time<-Short_stdJD$year - min(Short_stdJD$year)#
#
Perc_human<-samples_df_long[grep("Short_Number_fires_human", samples_df_long$variable),]#
Perc_human$time<-Perc_human$year - min(Perc_human$year)#
#
# create a list of these characteristics to pass to function below#
fire_chars<-list(MODIS_numfires, MTBS_numfires, Short_numfires, MODIS_meanFRP, MODIS_maxFRP, MTBS_meanArea, MTBS_maxArea,  Short_meanArea, Short_maxArea, MTBS_sumArea, Short_sumArea, MTBS_stdJD, MODIS_stdJD, Short_stdJD, Perc_human)
grouped_list_eco=vector("list", 15)#
for (i in 1:15){#
  grouped_list_eco[[i]]<-mean_annual_value_by_eco(fire_chars[[i]])#
}
names(grouped_list_eco)<-names_vector#
#
#fix the years#
for(i in c(1,4, 5, 13)){#
  grouped_list_eco[[i]]$year<-grouped_list_eco[[i]]$time+2003#
}#
#
for(i in c(2, 6, 7, 10, 12)){#
  grouped_list_eco[[i]]$year<-grouped_list_eco[[i]]$time+1984#
}#
#
for(i in c(3, 8, 9, 11, 14, 15)){#
  grouped_list_eco[[i]]$year<-grouped_list_eco[[i]]$time+1992#
}#
###	if(length(unique(samples_ign_mean_eco_each[[n]][which(!is.na(samples_ign_mean_eco_each[[n]]$ign)),]$ign))==2){#
#
# Fit linear model for each ecoregion#
library(nlme)#
lm_slope_list_human_eco<-vector("list", 15)#
for (i in c(1:11, 13:15)){#
  for (n in 1:10){#
  	lm_slope_list_human_eco[[i]][n]<-(summary(lmList(value ~ time | ign, data=fire_chars[[i]][fire_chars[[i]]$ecoregion==eco_names[n]& fire_chars[[i]]$ign=="Human",], na.action=na.omit))$coefficients[5])#
  }#
}#
#
for (i in 12){#
  for (n in c(1:2, 4:10)){#
  	lm_slope_list_human_eco[[i]][n]<-(summary(lmList(value ~ time | ign, data=fire_chars[[i]][fire_chars[[i]]$ecoregion==eco_names[n]& fire_chars[[i]]$ign=="Human",], na.action=na.omit))$coefficients[5])#
  }#
}#
#
lm_sig_list_human_eco<-vector("list", 15)#
for (i in c(1:11, 13:15)){#
  for (n in 1:10){#
  	lm_sig_list_human_eco[[i]][n]<-(summary(lmList(value ~ time | ign, data=fire_chars[[i]][fire_chars[[i]]$ecoregion==eco_names[n]& fire_chars[[i]]$ign=="Human",], na.action=na.omit))$coefficients[8])#
  }#
}#
#
for (i in 12){#
  for (n in c(1:2, 4:10)){#
  	lm_sig_list_human_eco[[i]][n]<-(summary(lmList(value ~ time | ign, data=fire_chars[[i]][fire_chars[[i]]$ecoregion==eco_names[n]& fire_chars[[i]]$ign=="Human",], na.action=na.omit))$coefficients[8])#
  }#
}#
lm_slope_list_lightning_eco<-vector("list", 15)#
for (i in 1:15){#
  for (n in 1:10){#
    if(length(unique(fire_chars[[i]][fire_chars[[i]]$ecoregion==eco_names[n],]$ign))==4){#
      lm_slope_list_lightning_eco[[i]][n]<-(summary(lmList(value ~ time | ign, data=fire_chars[[i]][fire_chars[[i]]$ecoregion==eco_names[n],], na.action=na.omit))$coefficients[15])#
    } else{#
      lm_slope_list_lightning_eco[[i]][n]<-"NA"#
    } #
  }#
}#
#
lm_sig_list_lightning_eco<-vector("list", 15)#
for (i in 1:15){#
  for (n in 1:10){#
    if(length(unique(fire_chars[[i]][fire_chars[[i]]$ecoregion==eco_names[n],]$ign))==4){#
      lm_sig_list_lightning_eco[[i]][n]<-summary(lmList(value ~ time | ign, data=fire_chars[[i]][fire_chars[[i]]$ecoregion==eco_names[n],], na.action=na.omit))$coefficients[24]#
    } else{#
      lm_sig_list_lightning_eco[[i]][n]<-"NA"#
    } #
  }#
}
eco_names<-unique(samples_df$ecoregion)[c(1, 6, 3, 9, 5, 2, 4, 11, 10, 12)]
names(grouped_list_eco)<-names_vector#
#
#fix the years#
for(i in c(1,4, 5, 13)){#
  grouped_list_eco[[i]]$year<-grouped_list_eco[[i]]$time+2003#
}#
#
for(i in c(2, 6, 7, 10, 12)){#
  grouped_list_eco[[i]]$year<-grouped_list_eco[[i]]$time+1984#
}#
#
for(i in c(3, 8, 9, 11, 14, 15)){#
  grouped_list_eco[[i]]$year<-grouped_list_eco[[i]]$time+1992#
}#
###	if(length(unique(samples_ign_mean_eco_each[[n]][which(!is.na(samples_ign_mean_eco_each[[n]]$ign)),]$ign))==2){#
#
# Fit linear model for each ecoregion#
library(nlme)#
lm_slope_list_human_eco<-vector("list", 15)#
for (i in c(1:11, 13:15)){#
  for (n in 1:10){#
  	lm_slope_list_human_eco[[i]][n]<-(summary(lmList(value ~ time | ign, data=fire_chars[[i]][fire_chars[[i]]$ecoregion==eco_names[n]& fire_chars[[i]]$ign=="Human",], na.action=na.omit))$coefficients[5])#
  }#
}#
#
for (i in 12){#
  for (n in c(1:2, 4:10)){#
  	lm_slope_list_human_eco[[i]][n]<-(summary(lmList(value ~ time | ign, data=fire_chars[[i]][fire_chars[[i]]$ecoregion==eco_names[n]& fire_chars[[i]]$ign=="Human",], na.action=na.omit))$coefficients[5])#
  }#
}#
#
lm_sig_list_human_eco<-vector("list", 15)#
for (i in c(1:11, 13:15)){#
  for (n in 1:10){#
  	lm_sig_list_human_eco[[i]][n]<-(summary(lmList(value ~ time | ign, data=fire_chars[[i]][fire_chars[[i]]$ecoregion==eco_names[n]& fire_chars[[i]]$ign=="Human",], na.action=na.omit))$coefficients[8])#
  }#
}#
#
for (i in 12){#
  for (n in c(1:2, 4:10)){#
  	lm_sig_list_human_eco[[i]][n]<-(summary(lmList(value ~ time | ign, data=fire_chars[[i]][fire_chars[[i]]$ecoregion==eco_names[n]& fire_chars[[i]]$ign=="Human",], na.action=na.omit))$coefficients[8])#
  }#
}#
lm_slope_list_lightning_eco<-vector("list", 15)#
for (i in 1:15){#
  for (n in 1:10){#
    if(length(unique(fire_chars[[i]][fire_chars[[i]]$ecoregion==eco_names[n],]$ign))==4){#
      lm_slope_list_lightning_eco[[i]][n]<-(summary(lmList(value ~ time | ign, data=fire_chars[[i]][fire_chars[[i]]$ecoregion==eco_names[n],], na.action=na.omit))$coefficients[15])#
    } else{#
      lm_slope_list_lightning_eco[[i]][n]<-"NA"#
    } #
  }#
}#
#
lm_sig_list_lightning_eco<-vector("list", 15)#
for (i in 1:15){#
  for (n in 1:10){#
    if(length(unique(fire_chars[[i]][fire_chars[[i]]$ecoregion==eco_names[n],]$ign))==4){#
      lm_sig_list_lightning_eco[[i]][n]<-summary(lmList(value ~ time | ign, data=fire_chars[[i]][fire_chars[[i]]$ecoregion==eco_names[n],], na.action=na.omit))$coefficients[24]#
    } else{#
      lm_sig_list_lightning_eco[[i]][n]<-"NA"#
    } #
  }#
}
for (i in 12){#
  for (n in c(3)){#
  	lm_sig_list_human_eco[[i]][n]<-(summary(lmList(value ~ time | ign, data=fire_chars[[i]][fire_chars[[i]]$ecoregion==eco_names[n]& fire_chars[[i]]$ign=="Human",], na.action=na.omit))$coefficients[8])#
  }#
}
lm_slope_human_eco<-unlist(lm_slope_list_human_eco)#
lm_sig_human_eco<-unlist(lm_sig_list_human_eco)#
lm_slope_lightning_eco<-as.numeric(unlist(lm_slope_list_lightning_eco))#
lm_sig_lightning_eco<-as.numeric(unlist(lm_sig_list_lightning_eco))#
lm_sig_lightning_eco<-ifelse(lm_sig_lightning_eco=="NaN", 1, lm_sig_lightning_eco)#
# Percent change for each over time period#
# Anthro ignitions#
initial_human<-vector("list", 15)#
final_human<-vector("list", 15)#
change_human<-vector("list", 15)#
perc_change_human<-vector("list", 15)#
#
for (i in 1:15){#
  for (n in 1:10){#
    initial_human[[i]][n]<-summary(lmList(value ~ time | ign, data=fire_chars[[i]][fire_chars[[i]]$ecoregion==eco_names[n]& fire_chars[[i]]$ign=="Human",], na.action=na.omit))$coefficients[1]#
    final_human[[i]][n]<-stats::predict.lm(lmList(value ~ time | ign, data=fire_chars[[i]][fire_chars[[i]]$ecoregion==eco_names[n] & fire_chars[[i]]$ign=="Human",], na.action=na.omit)[[1]], newdata=data.frame(time=(max(fire_chars[[i]]$time)-min(fire_chars[[i]]$time))))#
    change_human[[i]][n]<-final_human[[i]][n]-initial_human[[i]][n]#
    perc_change_human[[i]][n]<-(change_human[[i]][n]/initial_human[[i]][n])*100#
  }#
}#
initial_light<-vector("list", 15)#
final_light<-vector("list", 15)
for (i in c(1:11, 13:15)){#
  for (n in 1:10){#
    initial_human[[i]][n]<-summary(lmList(value ~ time | ign, data=fire_chars[[i]][fire_chars[[i]]$ecoregion==eco_names[n]& fire_chars[[i]]$ign=="Human",], na.action=na.omit))$coefficients[1]#
    final_human[[i]][n]<-stats::predict.lm(lmList(value ~ time | ign, data=fire_chars[[i]][fire_chars[[i]]$ecoregion==eco_names[n] & fire_chars[[i]]$ign=="Human",], na.action=na.omit)[[1]], newdata=data.frame(time=(max(fire_chars[[i]]$time)-min(fire_chars[[i]]$time))))#
    change_human[[i]][n]<-final_human[[i]][n]-initial_human[[i]][n]#
    perc_change_human[[i]][n]<-(change_human[[i]][n]/initial_human[[i]][n])*100#
  }#
}
for (i in 12){#
  for (n in c(1:2, 4:10)){#
    initial_human[[i]][n]<-summary(lmList(value ~ time | ign, data=fire_chars[[i]][fire_chars[[i]]$ecoregion==eco_names[n]& fire_chars[[i]]$ign=="Human",], na.action=na.omit))$coefficients[1]#
    final_human[[i]][n]<-stats::predict.lm(lmList(value ~ time | ign, data=fire_chars[[i]][fire_chars[[i]]$ecoregion==eco_names[n] & fire_chars[[i]]$ign=="Human",], na.action=na.omit)[[1]], newdata=data.frame(time=(max(fire_chars[[i]]$time)-min(fire_chars[[i]]$time))))#
    change_human[[i]][n]<-final_human[[i]][n]-initial_human[[i]][n]#
    perc_change_human[[i]][n]<-(change_human[[i]][n]/initial_human[[i]][n])*100#
  }#
}
initial_light<-vector("list", 15)#
final_light<-vector("list", 15)#
#
for (i in 1:15){#
  for (n in 1:10){#
    if(length(unique(fire_chars[[i]][fire_chars[[i]]$ecoregion==eco_names[n],]$ign))==4){#
      initial_light[[i]][n]<-summary(lmList(value ~ time | ign, data=fire_chars[[i]][fire_chars[[i]]$ecoregion==eco_names[n],], na.action=na.omit))$coefficients[3]#
      final_light[[i]][n]<-stats::predict.lm(lmList(value ~ time | ign, data=fire_chars[[i]][fire_chars[[i]]$ecoregion==eco_names[n],], na.action=na.omit)[[3]], newdata=data.frame(time=(max(fire_chars[[i]]$time)-min(fire_chars[[i]]$time))))#
    } else{		#
      initial_light[[i]][n]<--9999#
      final_light[[i]][n]<--9999#
    }	#
  }#
}#
change_light<-vector("list", 15)#
perc_change_light<-vector("list", 15)
for (i in 1:15){#
  for (n in 1:10){#
    change_light[[i]][n]<--9999#
    perc_change_light[[i]][n]<-9999#
  }#
}#
#
for (i in 1:15){#
  for (n in (c(2, 5, 7, 9))){#
    change_light[[i]][n]<-final_light[[i]][n]-initial_light[[i]][n]#
    perc_change_light[[i]][n]<-(change_light[[i]][n]/initial_light[[i]][n])*100	#
  }#
}
perc_change_human_eco<-unlist(perc_change_human)#
perc_change_lightning_eco<-unlist(perc_change_light)#
# Slopes of ign groups by ecoregion#
slopes_eco<-data.frame(matrix(NA, nrow = 150, ncol = 4))#
slopes_eco[,1]<-eco_names#
#
for (i in 1:150){#
  slopes_eco[i, 2]<-ifelse(lm_slope_human_eco[i]=="NA", "NA",#
                           paste0(round(lm_slope_human_eco[i],2), #
                                  ifelse(lm_sig_human_eco[i]>0.1, " ",#
                                         ifelse(lm_sig_human_eco[i]>0.05 & lm_sig_human_eco[i]<=0.1, "*",#
                                                ifelse(lm_sig_human_eco[i]>0.01 & lm_sig_human_eco[i]<=0.05, "**",#
                                                       ifelse(lm_sig_human_eco[i]<=0.01, "***", "    "))))))#
  slopes_eco[i, 3]<-ifelse(lm_slope_lightning_eco[i]=="NA", "NA",#
                           paste0(round(lm_slope_lightning_eco[i], 2), #
                                  ifelse(as.numeric(lm_sig_lightning_eco[i])>0.1, " ",#
                                         ifelse(as.numeric(lm_sig_lightning_eco[i])>0.05 & lm_sig_lightning_eco[i]<=0.1, "*",#
                                                ifelse(as.numeric(lm_sig_lightning_eco[i])>0.01 & lm_sig_lightning_eco[i]<=0.05, "**",#
                                                       ifelse(as.numeric(lm_sig_lightning_eco[i])<=0.01, "***", "    "))))))#
  slopes_eco[i, 4]<-ifelse(is.na(lm_slope_lightning_eco[i]), "Dominated by human ign only",#
                           ifelse(lm_slope_human_eco[i]>lm_slope_lightning_eco[i] & lm_sig_human_eco[i]<=0.1, "Human",#
                                  ifelse(lm_slope_human_eco[i]>lm_slope_lightning_eco[i] & lm_sig_human_eco[i]>0.1, "Human, not sig",#
                                         ifelse(lm_slope_lightning_eco[i]>lm_slope_human_eco[i] & lm_sig_lightning_eco[i]<=0.1, "Lightning",#
                                                ifelse(lm_slope_lightning_eco[i]>lm_slope_human_eco[i] & lm_sig_lightning_eco[i]>0.1, "Lightning, not sig",#
                                                       "NA")))))	#
  slopes_eco[i, 5]<-perc_change_human_eco[i]	#
  slopes_eco[i, 6]<-perc_change_lightning_eco[i]	#
  slopes_eco[i, 7]<-ifelse(lm_slope_human_eco[i]=="NA", "NA", round(lm_slope_human_eco[i],2))#
  slopes_eco[i, 8]<-ifelse(lm_slope_lightning_eco[i]=="NA", "NA", round(lm_slope_lightning_eco[i],2))#
}#
#
names(slopes_eco)<-c("Ecoregion", "Human", "Lightning", "Higher", "Percent_change_Human", "Percent_change_Lightning", "Human2", "Lightning2")#
slopes_eco
round(slopes_eco[,5],2)
round(slopes_eco[,4],2)
slopes_eco[,4]
change_ign_eco_map<-slopes_eco[,c(1,4, 7,8)]#
change_ign_eco_map$char<-rep(names_vector, each=10)#
head(change_ign_eco_map)#
#
# Make it a list for each characteristic#
# In a weird order#
change_ign_eco_map_list<-split(change_ign_eco_map, as.factor(change_ign_eco_map$char))#
# fix the order#
change_ign_eco_map_list1<-change_ign_eco_map_list[c(names_vector)]#
# merge with ecoregion, x, y, and ign?#
new_df_time<-vector('list', 15)#
for (i in 1:15){#
  new_df_time[[i]]<-merge(samples_df[,c(377:379, 381)], change_ign_eco_map_list1[[i]], by.x="ecoregion", by.y="Ecoregion")#
}#
make_gg_eco_time<-function(character){#
  ggplot(new_df_time[[character]],  aes(x, y)) + #
    coord_equal() +#
    geom_point(aes(color = factor(Higher))) +  #
    scale_color_manual(values = c("Dominated by human ign only"="firebrick4", "Human" = "firebrick2", "Human, not sig"="bisque2", "Lightning"="dodgerblue3", "Lightning, not sig"="slategray2"))+#
    labs(colour="Ignition source with higher value")+#
    theme(plot.title = element_text(hjust = 0.5))+#
    theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(),#
          panel.background = element_blank(), axis.line = element_blank(), axis.text.x=element_blank(), axis.text.y=element_blank(),axis.ticks.x=element_blank(), axis.ticks.y=element_blank(), axis.title.x=element_blank(), axis.title.y=element_blank())+#
    geom_polygon(data=overlay, aes(x=long, y=lat, group=group), fill=NA, colour="black")#
}
ggarrange(make_gg_eco_time(1)+ggtitle(names_vector[1]), #
          make_gg_eco_time(2)+ggtitle(names_vector[2]), #
          make_gg_eco_time(3)+ggtitle(names_vector[3]), #
          make_gg_eco_time(4)+ggtitle(names_vector[4]),  #
          make_gg_eco_time(5)+ ggtitle(names_vector[5]), #
          make_gg_eco_time(6)+	 ggtitle(names_vector[6]), #
          ncol=3, nrow=2, legend=c("none"))
make_gg_eco_time<-function(character){#
  ggplot(new_df_time[[character]],  aes(x, y)) + #
    coord_equal() +#
    geom_point(aes(color = factor(Higher))) +  #
    ggtitle(paste0(letters[char], ". ", names_vector[char]))+#
    scale_color_manual(values = c("Dominated by human ign only"="firebrick4", "Human" = "firebrick2", "Human, not sig"="bisque2", "Lightning"="dodgerblue3", "Lightning, not sig"="slategray2"))+#
    labs(colour="Ignition source with higher value")+#
    theme(plot.title = element_text(hjust = 0.5))+#
    theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(),#
          panel.background = element_blank(), axis.line = element_blank(), axis.text.x=element_blank(), axis.text.y=element_blank(),axis.ticks.x=element_blank(), axis.ticks.y=element_blank(), axis.title.x=element_blank(), axis.title.y=element_blank())+#
    geom_polygon(data=overlay, aes(x=long, y=lat, group=group), fill=NA, colour="black")#
}
make_gg_eco_time<-function(character){#
  ggplot(new_df_time[[character]],  aes(x, y)) + #
    coord_equal() +#
    geom_point(aes(color = factor(Higher))) +  #
    ggtitle(paste0(letters[character], ". ", names_vector[character]))+#
    scale_color_manual(values = c("Dominated by human ign only"="firebrick4", "Human" = "firebrick2", "Human, not sig"="bisque2", "Lightning"="dodgerblue3", "Lightning, not sig"="slategray2"))+#
    labs(colour="Ignition source with higher value")+#
    theme(plot.title = element_text(hjust = 0.5))+#
    theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(),#
          panel.background = element_blank(), axis.line = element_blank(), axis.text.x=element_blank(), axis.text.y=element_blank(),axis.ticks.x=element_blank(), axis.ticks.y=element_blank(), axis.title.x=element_blank(), axis.title.y=element_blank())+#
    geom_polygon(data=overlay, aes(x=long, y=lat, group=group), fill=NA, colour="black")#
}
make_gg_eco_time(1)
ggarrange(make_gg_eco_time(1), #
          make_gg_eco_time(2), #
          make_gg_eco_time(3), #
          make_gg_eco_time(4),  #
          make_gg_eco_time(5), #
          make_gg_eco_time(6), #
          ncol=3, nrow=2, legend=c("none"))
ggarrange(make_gg_eco_time(7),  #
          make_gg_eco_time(8),  #
          make_gg_eco_time(9), #
          make_gg_eco_time(10), #
          make_gg_eco_time(11), #
          make_gg_eco_time(12), #
         ncol=3, nrow=2, legend=c("none"))
ggarrange(make_gg_eco_time(13), #
          make_gg_eco_time(14),  #
          make_gg_eco_time(15),  #
          ncol=3, nrow=1, legend=c("none"))
# make each column + anthro a list of data frames#
data_list<-vector("list", 15)																# list of data#
regression_list<-vector("list", 15)															# regressions#
davies_list<-vector("list", 15)																# Davies test on regressions#
num_breaks<-vector("numeric", 15)														# number of breaks#
davies.significance<-vector("character", 15)													# significance of Davies test (for last significant one)#
adj.r.square<-vector("numeric", length=15)													# adjusted r of model (regression or segmented)#
segmented_list<-vector("list", 15)															# segmented regressions#
slopes<-vector("character", length=15)														# p value of model (regression or segmented)#
slopes2<-vector("numeric", length=15)														# p value of model (regression or segmented)#
breaks<-vector("numeric", length=15)														# p value of model (regression or segmented)#
#
set.seed(167)#
#
# make data list of characteristics and percent ign#
for(i in 1:length(data_list)){#
  data_list[[i]]<-na.omit(data.frame(samples_df[,i], samples_df[,15]))		# each item in list is data frame of each fire characteristic and anthro ign#
  names(data_list[[i]])<-c("depend.var", "anthro")						# name columns of each dataframe in list#
  data_list[[i]]<-data_list[[i]][data_list[[i]]$depend.var>0,]			# remove 0 values of dependent variable#
  regression_list[[i]]<-(lm(depend.var~anthro, data=data_list[[i]]))		# run a linear regression on the data#
  davies_list[[i]]<-davies.test(regression_list[[i]], seg.Z=~anthro, k = 10)	# Davies' test on each regression model object. If significant, there's a breakpoint#
  if(davies_list[[i]]$p.value>0.05){									# If the Davies' test does not indicate that there is a breakpoint...#
    num_breaks[i]<-0											#  the number of breaks is 0#
    davies.significance[[i]]<-"--"									# Davies is not significant#
    adj.r.square[i]<-round(summary(regression_list[[i]])$adj.r.square,3)	# The adjused r2 is from the regression#
    segmented_list[[i]]<-"NA"																	# dont need to segment#
    slopes[i]<-paste0(round(summary(regression_list[[i]])$coefficients[2,1],2), ifelse(summary(regression_list[[i]])$coefficients[2,4]<=0.01, "***", ifelse(summary(regression_list[[i]])$coefficients[2,4]>0.01&summary(regression_list[[i]])$coefficients[2,4]<=0.05, "**", ifelse(summary(regression_list[[i]])$coefficients[2,4]>0.05&summary(regression_list[[i]])$coefficients[2,4]<=0.1, "*", "--"))))																						# slope from the regression, other slopes not relevant#
    slopes2[i]<-"NA"	#
  } else {																												# If the Davies' test does indicate that there is at least one breakpoint...#
    num_breaks[i]<-1#
    segmented_list[[i]]<-"TBD"#
  }#
}#
#
davies.significance[[i]]<-"TBD"#
adj.r.square[i]<-"TBD"#
slopes[i]<-"TBD"#
slopes2[i]<-"TBD"
num_breaks
davies.significance
# make data list of characteristics and percent ign#
for(i in 1:length(data_list)){#
  data_list[[i]]<-na.omit(data.frame(samples_df[,i], samples_df[,15]))		# each item in list is data frame of each fire characteristic and anthro ign#
  names(data_list[[i]])<-c("depend.var", "anthro")						# name columns of each dataframe in list#
  data_list[[i]]<-data_list[[i]][data_list[[i]]$depend.var>0,]			# remove 0 values of dependent variable#
  regression_list[[i]]<-(lm(depend.var~anthro, data=data_list[[i]]))		# run a linear regression on the data#
  davies_list[[i]]<-davies.test(regression_list[[i]], seg.Z=~anthro, k = 10)	# Davies' test on each regression model object. If significant, there's a breakpoint#
  if(davies_list[[i]]$p.value>0.05){									# If the Davies' test does not indicate that there is a breakpoint...#
    num_breaks[i]<-0											#  the number of breaks is 0#
    davies.significance[[i]]<-"--"									# Davies is not significant#
    adj.r.square[i]<-round(summary(regression_list[[i]])$adj.r.square,3)	# The adjused r2 is from the regression#
    segmented_list[[i]]<-"NA"																	# dont need to segment#
    slopes[i]<-paste0(round(summary(regression_list[[i]])$coefficients[2,1],2), ifelse(summary(regression_list[[i]])$coefficients[2,4]<=0.01, "***", ifelse(summary(regression_list[[i]])$coefficients[2,4]>0.01&summary(regression_list[[i]])$coefficients[2,4]<=0.05, "**", ifelse(summary(regression_list[[i]])$coefficients[2,4]>0.05&summary(regression_list[[i]])$coefficients[2,4]<=0.1, "*", "--"))))																						# slope from the regression, other slopes not relevant#
    slopes2[i]<-"NA"	#
  } else {																												# If the Davies' test does indicate that there is at least one breakpoint...#
    num_breaks[i]<-1#
    segmented_list[[i]]<-"TBD"#
  }#
}#
#
davies.significance[[i]]<-"TBD"#
adj.r.square[i]<-"TBD"#
slopes[i]<-"TBD"#
slopes2[i]<-"TBD"
# run the segmented models#
for (i in 1:15){#
  if(segmented_list[[i]]!="NA"){#
    bo=0#
    while(bo!=1000){#
      segmented_list[[i]] = try(segmented::segmented(lm(depend.var~anthro, data=data_list[[i]]), seg.Z =~anthro, psi = c(.7)),silent=TRUE)#
      if (class(segmented_list[[i]])=="try-error") {#
        bo <- bo+1#
        print(bo)#
      } else#
        break#
    }#
  }#
}#
for (i in 1:15) {#
  if(num_breaks[i]=="1") {	#
    davies.significance[[i]]<-round(davies_list[[i]]$p.value, 3)#
    adj.r.square[i]<-round(summary(segmented_list[[i]])$adj.r.square,3)#
    slopes[i]<-paste0(round(summary(segmented_list[[i]])$coefficients[2,1], 2), ifelse(summary(segmented_list[[i]])$coefficients[2,4]<=0.01, "***", ifelse(summary(segmented_list[[i]])$coefficients[2,4]>0.01&summary(segmented_list[[i]])$coefficients[2,4]<=0.05, "**", ifelse(summary(segmented_list[[i]])$coefficients[2,4]>0.05&summary(segmented_list[[i]])$coefficients[2,4]<=0.1, "*", "--"))))#
    slopes2[i]<-paste0(round((summary(segmented_list[[i]])$coefficients[2,1]+summary(segmented_list[[i]])$coefficients[3,1]), 2),  ifelse(summary(segmented_list[[i]])$coefficients[3,4]<=0.01, "***", ifelse(summary(segmented_list[[i]])$coefficients[3,4]>0.01&summary(segmented_list[[i]])$coefficients[3,4]<=0.05, "**", ifelse(summary(segmented_list[[i]])$coefficients[3,4]>0.05&summary(segmented_list[[i]])$coefficients[3,4]<=0.1, "*", "--"))))#
    breaks[i]<-segmented_list[[i]]$psi[2] #
  }#
}
##### To make the figures#
# plot the stuff with the appropriate model#
#
plot_segmented<- function(number){#
  for (i in number:number){#
    par("mar"=c(5,5,1,1))#
    plot(data_list[[i]]$anthro, data_list[[i]]$depend.var, #
         xlab="Proportion anthropogenic ignitions", #
         ylab=units_simple[i], #
         cex.lab=1.5, col="lightgray", #
         main=names_no_units[i])#
    if (num_breaks[i]=="1"){#
      plot(segmented_list[[i]], rug=FALSE, add=TRUE)#
      lines(segmented_list[[i]], col="blue")#
    } else if (num_breaks[i]=="0"){#
      abline(regression_list[[i]])		}#
  }#
}#
#
ggplot_segmented<- function(i){#
    if (num_breaks[i]=="1"){#
      ggplot(data_list[[i]], aes(x=anthro, y=depend.var)) +#
        geom_point(alpha = 0.5, color = "grey60") +#
        xlab("Proportion anthropogenic ignitions") +#
        ylab(units_simple[i]) +#
        ggtitle(names_no_units[i]) +#
        scale_y_continuous(trans = "log10")+#
        theme_pubr() +#
        geom_line(aes(y = predict(segmented_list[[i]])), lwd=1)+#
        # geom_segment(aes(x = segmented_list[[i]]$psi[2] - segmented_list[[i]]$psi[3],#
        #              xend = segmented_list[[i]]$psi[2] + segmented_list[[i]]$psi[3],#
        #              y = 1, yend=1),#
        #              color = "blue", lwd = 1.5) +#
        # geom_point(aes(x = segmented_list[[i]]$psi[2],y=1), color = "blue", size = 3)#
        geom_vline(xintercept = segmented_list[[i]]$psi[2], lty =1) +#
        geom_vline(xintercept = segmented_list[[i]]$psi[2]- segmented_list[[i]]$psi[3], lty =2) +#
        geom_vline(xintercept = segmented_list[[i]]$psi[2]+ segmented_list[[i]]$psi[3], lty =2) #
    } else if (num_breaks[i]=="0"){#
      ggplot(data_list[[i]], aes(x=anthro, y=depend.var)) +#
        geom_point(alpha = 0.5, color = "grey60") +#
        xlab("Proportion anthropogenic ignitions") +#
        ylab(units_simple[i]) +#
        ggtitle(names_no_units[i]) +#
        scale_y_continuous(trans = "log10")+#
        theme_pubr() +#
        geom_line(aes(y = predict(regression_list[[i]])), lwd=1)#
        	}#
}#
#
# All variables#
par(mfrow=c(3,5))#
for (i in 1:14){#
  plot_segmented(i)#
}
par(mfrow=c(2,2))#
for (i in c(4, 8, 3, 14)){#
  plot_segmented(i)#
}#
#
# ggplot figure 3#
ggarrange(#
  ggplot_segmented(4),#
  ggplot_segmented(8),#
  ggplot_segmented(3),#
  ggplot_segmented(14),#
  nrow=2,#
  ncol = 2
)#
ggsave("figure_3_ggplotted_vlines.png")#
slopes[c(4, 8, 3, 14)]#
slopes2[c(4, 8, 3, 14)]
seg_table
seg_table<-cbind(adj.r.square, num_breaks, breaks, slopes, slopes2)
seg_table
data_list<-vector("list", 15)																# list of data#
regression_list<-vector("list", 15)															# regressions#
davies_list<-vector("list", 15)																# Davies test on regressions#
num_breaks<-vector("numeric", 15)														# number of breaks#
davies.significance<-vector("character", 15)													# significance of Davies test (for last significant one)#
adj.r.square<-vector("numeric", length=15)													# adjusted r of model (regression or segmented)#
segmented_list<-vector("list", 15)															# segmented regressions#
slopes<-vector("character", length=15)														# p value of model (regression or segmented)#
slopes2<-vector("numeric", length=15)														# p value of model (regression or segmented)#
breaks<-vector("numeric", length=15)														# p value of model (regression or segmented)#
#
set.seed(167)#
#
# make data list of characteristics and percent ign#
for(i in 1:length(data_list)){#
  data_list[[i]]<-na.omit(data.frame(samples_df[,i], samples_df[,15]))		# each item in list is data frame of each fire characteristic and anthro ign#
  names(data_list[[i]])<-c("depend.var", "anthro")						# name columns of each dataframe in list#
  data_list[[i]]<-data_list[[i]][data_list[[i]]$depend.var>0,]			# remove 0 values of dependent variable#
  regression_list[[i]]<-(lm(depend.var~anthro, data=data_list[[i]]))		# run a linear regression on the data#
  davies_list[[i]]<-davies.test(regression_list[[i]], seg.Z=~anthro, k = 10)	# Davies' test on each regression model object. If significant, there's a breakpoint#
  if(davies_list[[i]]$p.value>0.05){									# If the Davies' test does not indicate that there is a breakpoint...#
    num_breaks[i]<-0											#  the number of breaks is 0#
    davies.significance[[i]]<-"--"									# Davies is not significant#
    adj.r.square[i]<-round(summary(regression_list[[i]])$adj.r.square,3)	# The adjused r2 is from the regression#
    segmented_list[[i]]<-"NA"																	# dont need to segment#
    slopes[i]<-paste0(round(summary(regression_list[[i]])$coefficients[2,1],2), ifelse(summary(regression_list[[i]])$coefficients[2,4]<=0.01, "***", ifelse(summary(regression_list[[i]])$coefficients[2,4]>0.01&summary(regression_list[[i]])$coefficients[2,4]<=0.05, "**", ifelse(summary(regression_list[[i]])$coefficients[2,4]>0.05&summary(regression_list[[i]])$coefficients[2,4]<=0.1, "*", "--"))))																						# slope from the regression, other slopes not relevant#
    slopes2[i]<-"NA"	#
  } else {																												# If the Davies' test does indicate that there is at least one breakpoint...#
    num_breaks[i]<-1#
    segmented_list[[i]]<-"TBD"#
  }#
}#
#
davies.significance[[i]]<-"TBD"#
adj.r.square[i]<-"TBD"#
slopes[i]<-"TBD"#
slopes2[i]<-"TBD"#
#
# Check it#
num_breaks#
davies.significance#
adj.r.square#
segmented_list#
slopes#
slopes2#
# run the segmented models#
for (i in 1:15){#
  if(segmented_list[[i]]!="NA"){#
    bo=0#
    while(bo!=1000){#
      segmented_list[[i]] = try(segmented::segmented(lm(depend.var~anthro, data=data_list[[i]]), seg.Z =~anthro, psi = c(.7)),silent=TRUE)#
      if (class(segmented_list[[i]])=="try-error") {#
        bo <- bo+1#
        print(bo)#
      } else#
        break#
    }#
  }#
}#
for (i in 1:15) {#
  if(num_breaks[i]=="1") {	#
    davies.significance[[i]]<-round(davies_list[[i]]$p.value, 3)#
    adj.r.square[i]<-round(summary(segmented_list[[i]])$adj.r.square,3)#
    slopes[i]<-paste0(round(summary(segmented_list[[i]])$coefficients[2,1], 2), ifelse(summary(segmented_list[[i]])$coefficients[2,4]<=0.01, "***", ifelse(summary(segmented_list[[i]])$coefficients[2,4]>0.01&summary(segmented_list[[i]])$coefficients[2,4]<=0.05, "**", ifelse(summary(segmented_list[[i]])$coefficients[2,4]>0.05&summary(segmented_list[[i]])$coefficients[2,4]<=0.1, "*", "--"))))#
    slopes2[i]<-paste0(round((summary(segmented_list[[i]])$coefficients[2,1]+summary(segmented_list[[i]])$coefficients[3,1]), 2),  ifelse(summary(segmented_list[[i]])$coefficients[3,4]<=0.01, "***", ifelse(summary(segmented_list[[i]])$coefficients[3,4]>0.01&summary(segmented_list[[i]])$coefficients[3,4]<=0.05, "**", ifelse(summary(segmented_list[[i]])$coefficients[3,4]>0.05&summary(segmented_list[[i]])$coefficients[3,4]<=0.1, "*", "--"))))#
    breaks[i]<-segmented_list[[i]]$psi[2] #
  }#
}
seg_table<-cbind(adj.r.square, num_breaks, breaks, slopes, slopes2)
seg_table
# make each column + anthro a list of data frames#
data_list<-vector("list", 15)																# list of data#
regression_list<-vector("list", 15)															# regressions#
davies_list<-vector("list", 15)																# Davies test on regressions#
num_breaks<-vector("numeric", 15)														# number of breaks#
davies.significance<-vector("character", 15)													# significance of Davies test (for last significant one)#
adj.r.square<-vector("numeric", length=15)													# adjusted r of model (regression or segmented)#
segmented_list<-vector("list", 15)															# segmented regressions#
slopes<-vector("character", length=15)														# p value of model (regression or segmented)#
slopes2<-vector("numeric", length=15)														# p value of model (regression or segmented)#
breaks<-vector("numeric", length=15)														# p value of model (regression or segmented)
# make data list of characteristics and percent ign#
for(i in 1:length(data_list)){#
  data_list[[i]]<-na.omit(data.frame(samples_df[,i], samples_df[,15]))		# each item in list is data frame of each fire characteristic and anthro ign#
  names(data_list[[i]])<-c("depend.var", "anthro")						# name columns of each dataframe in list#
  data_list[[i]]<-data_list[[i]][data_list[[i]]$depend.var>0,]			# remove 0 values of dependent variable#
  regression_list[[i]]<-(lm(depend.var~anthro, data=data_list[[i]]))		# run a linear regression on the data#
  davies_list[[i]]<-davies.test(regression_list[[i]], seg.Z=~anthro, k = 10)	# Davies' test on each regression model object. If significant, there's a breakpoint#
  if(davies_list[[i]]$p.value>0.05){									# If the Davies' test does not indicate that there is a breakpoint...#
    num_breaks[i]<-0											#  the number of breaks is 0#
    davies.significance[[i]]<-"--"									# Davies is not significant#
    adj.r.square[i]<-round(summary(regression_list[[i]])$adj.r.square,3)	# The adjused r2 is from the regression#
    segmented_list[[i]]<-"NA"																	# dont need to segment#
    slopes[i]<-paste0(round(summary(regression_list[[i]])$coefficients[2,1],2), ifelse(summary(regression_list[[i]])$coefficients[2,4]<=0.01, "***", ifelse(summary(regression_list[[i]])$coefficients[2,4]>0.01&summary(regression_list[[i]])$coefficients[2,4]<=0.05, "**", ifelse(summary(regression_list[[i]])$coefficients[2,4]>0.05&summary(regression_list[[i]])$coefficients[2,4]<=0.1, "*", "--"))))																						# slope from the regression, other slopes not relevant#
    slopes2[i]<-"NA"	#
  } else {																												# If the Davies' test does indicate that there is at least one breakpoint...#
    num_breaks[i]<-1#
    segmented_list[[i]]<-"TBD"#
  }#
}#
#
davies.significance[[i]]<-"TBD"#
adj.r.square[i]<-"TBD"#
slopes[i]<-"TBD"#
slopes2[i]<-"TBD"#
#
# Check it#
num_breaks#
davies.significance#
adj.r.square#
segmented_list#
slopes#
slopes2#
# run the segmented models#
for (i in 1:15){#
  if(segmented_list[[i]]!="NA"){#
    bo=0#
    while(bo!=1000){#
      segmented_list[[i]] = try(segmented::segmented(lm(depend.var~anthro, data=data_list[[i]]), seg.Z =~anthro, psi = c(.7)),silent=TRUE)#
      if (class(segmented_list[[i]])=="try-error") {#
        bo <- bo+1#
        print(bo)#
      } else#
        break#
    }#
  }#
}#
for (i in 1:15) {#
  if(num_breaks[i]=="1") {	#
    davies.significance[[i]]<-round(davies_list[[i]]$p.value, 3)#
    adj.r.square[i]<-round(summary(segmented_list[[i]])$adj.r.square,3)#
    slopes[i]<-paste0(round(summary(segmented_list[[i]])$coefficients[2,1], 2), ifelse(summary(segmented_list[[i]])$coefficients[2,4]<=0.01, "***", ifelse(summary(segmented_list[[i]])$coefficients[2,4]>0.01&summary(segmented_list[[i]])$coefficients[2,4]<=0.05, "**", ifelse(summary(segmented_list[[i]])$coefficients[2,4]>0.05&summary(segmented_list[[i]])$coefficients[2,4]<=0.1, "*", "--"))))#
    slopes2[i]<-paste0(round((summary(segmented_list[[i]])$coefficients[2,1]+summary(segmented_list[[i]])$coefficients[3,1]), 2),  ifelse(summary(segmented_list[[i]])$coefficients[3,4]<=0.01, "***", ifelse(summary(segmented_list[[i]])$coefficients[3,4]>0.01&summary(segmented_list[[i]])$coefficients[3,4]<=0.05, "**", ifelse(summary(segmented_list[[i]])$coefficients[3,4]>0.05&summary(segmented_list[[i]])$coefficients[3,4]<=0.1, "*", "--"))))#
    breaks[i]<-segmented_list[[i]]$psi[2] #
  }#
}
seg_table<-cbind(adj.r.square, num_breaks, breaks, slopes, slopes2)
seg_table
num_breaks
davies.significance
adj.r.square
segmented_list
slopes
slopes2
data_list<-vector("list", 15)																# list of data#
regression_list<-vector("list", 15)															# regressions#
davies_list<-vector("list", 15)																# Davies test on regressions#
num_breaks<-vector("numeric", 15)														# number of breaks#
davies.significance<-vector("character", 15)													# significance of Davies test (for last significant one)#
adj.r.square<-vector("numeric", length=15)													# adjusted r of model (regression or segmented)#
segmented_list<-vector("list", 15)															# segmented regressions#
slopes<-vector("character", length=15)														# p value of model (regression or segmented)#
slopes2<-vector("numeric", length=15)														# p value of model (regression or segmented)#
breaks<-vector("numeric", length=15)														# p value of model (regression or segmented)
names(samples_df)
data_list
data_list<-vector("list", 15)																# list of data#
regression_list<-vector("list", 15)															# regressions#
davies_list<-vector("list", 15)																# Davies test on regressions#
num_breaks<-vector("numeric", 15)														# number of breaks#
davies.significance<-vector("character", 15)													# significance of Davies test (for last significant one)#
adj.r.square<-vector("numeric", length=15)													# adjusted r of model (regression or segmented)#
segmented_list<-vector("list", 15)															# segmented regressions#
slopes<-vector("character", length=15)														# p value of model (regression or segmented)#
slopes2<-vector("numeric", length=15)														# p value of model (regression or segmented)#
breaks<-vector("numeric", length=15)														# p value of model (regression or segmented)#
#
set.seed(167)#
#
# make data list of characteristics and percent ign#
for(i in 1:length(data_list)){#
  data_list[[i]]<-na.omit(data.frame(samples_df[,i], samples_df[,15]))		# each item in list is data frame of each fire characteristic and anthro ign#
  names(data_list[[i]])<-c("depend.var", "anthro")						# name columns of each dataframe in list#
  data_list[[i]]<-data_list[[i]][data_list[[i]]$depend.var>0,]			# remove 0 values of dependent variable#
  regression_list[[i]]<-(lm(depend.var~anthro, data=data_list[[i]]))		# run a linear regression on the data#
  davies_list[[i]]<-davies.test(regression_list[[i]], seg.Z=~anthro, k = 10)	# Davies' test on each regression model object. If significant, there's a breakpoint#
  if(davies_list[[i]]$p.value>0.05){									# If the Davies' test does not indicate that there is a breakpoint...#
    num_breaks[i]<-0											#  the number of breaks is 0#
    davies.significance[[i]]<-"--"									# Davies is not significant#
    adj.r.square[i]<-round(summary(regression_list[[i]])$adj.r.square,3)	# The adjused r2 is from the regression#
    segmented_list[[i]]<-"NA"																	# dont need to segment#
    slopes[i]<-paste0(round(summary(regression_list[[i]])$coefficients[2,1],2), ifelse(summary(regression_list[[i]])$coefficients[2,4]<=0.01, "***", ifelse(summary(regression_list[[i]])$coefficients[2,4]>0.01&summary(regression_list[[i]])$coefficients[2,4]<=0.05, "**", ifelse(summary(regression_list[[i]])$coefficients[2,4]>0.05&summary(regression_list[[i]])$coefficients[2,4]<=0.1, "*", "--"))))																						# slope from the regression, other slopes not relevant#
    slopes2[i]<-"NA"	#
  } else {																												# If the Davies' test does indicate that there is at least one breakpoint...#
    num_breaks[i]<-1#
    segmented_list[[i]]<-"TBD"#
  }#
}#
#
davies.significance[[i]]<-"TBD"#
adj.r.square[i]<-"TBD"#
slopes[i]<-"TBD"#
slopes2[i]<-"TBD"#
#
# Check it#
num_breaks#
davies.significance#
adj.r.square#
segmented_list#
slopes#
slopes2#
# run the segmented models#
for (i in 1:15){#
  if(segmented_list[[i]]!="NA"){#
    bo=0#
    while(bo!=1000){#
      segmented_list[[i]] = try(segmented::segmented(lm(depend.var~anthro, data=data_list[[i]]), seg.Z =~anthro, psi = c(.7)),silent=TRUE)#
      if (class(segmented_list[[i]])=="try-error") {#
        bo <- bo+1#
        print(bo)#
      } else#
        break#
    }#
  }#
}#
for (i in 1:15) {#
  if(num_breaks[i]=="1") {	#
    davies.significance[[i]]<-round(davies_list[[i]]$p.value, 3)#
    adj.r.square[i]<-round(summary(segmented_list[[i]])$adj.r.square,3)#
    slopes[i]<-paste0(round(summary(segmented_list[[i]])$coefficients[2,1], 2), ifelse(summary(segmented_list[[i]])$coefficients[2,4]<=0.01, "***", ifelse(summary(segmented_list[[i]])$coefficients[2,4]>0.01&summary(segmented_list[[i]])$coefficients[2,4]<=0.05, "**", ifelse(summary(segmented_list[[i]])$coefficients[2,4]>0.05&summary(segmented_list[[i]])$coefficients[2,4]<=0.1, "*", "--"))))#
    slopes2[i]<-paste0(round((summary(segmented_list[[i]])$coefficients[2,1]+summary(segmented_list[[i]])$coefficients[3,1]), 2),  ifelse(summary(segmented_list[[i]])$coefficients[3,4]<=0.01, "***", ifelse(summary(segmented_list[[i]])$coefficients[3,4]>0.01&summary(segmented_list[[i]])$coefficients[3,4]<=0.05, "**", ifelse(summary(segmented_list[[i]])$coefficients[3,4]>0.05&summary(segmented_list[[i]])$coefficients[3,4]<=0.1, "*", "--"))))#
    breaks[i]<-segmented_list[[i]]$psi[2] #
  }#
}
seg_table<-cbind(adj.r.square, num_breaks, breaks, slopes, slopes2)
seg_table
ggplot_segmented<- function(i){#
    if (num_breaks[i]=="1"){#
      ggplot(data_list[[i]], aes(x=anthro, y=depend.var)) +#
        geom_point(alpha = 0.5, color = "grey60") +#
        xlab("Proportion anthropogenic ignitions") +#
        ylab(units_simple[i]) +#
        ggtitle(names_no_units[i]) +#
        scale_y_continuous(trans = "log10")+#
        theme_pubr() +#
        geom_line(aes(y = predict(segmented_list[[i]])), lwd=1)+#
        # geom_segment(aes(x = segmented_list[[i]]$psi[2] - segmented_list[[i]]$psi[3],#
        #              xend = segmented_list[[i]]$psi[2] + segmented_list[[i]]$psi[3],#
        #              y = 1, yend=1),#
        #              color = "blue", lwd = 1.5) +#
        # geom_point(aes(x = segmented_list[[i]]$psi[2],y=1), color = "blue", size = 3)#
        geom_vline(xintercept = segmented_list[[i]]$psi[2], lty =1) +#
        geom_vline(xintercept = segmented_list[[i]]$psi[2]- segmented_list[[i]]$psi[3], lty =2) +#
        geom_vline(xintercept = segmented_list[[i]]$psi[2]+ segmented_list[[i]]$psi[3], lty =2) #
    } else if (num_breaks[i]=="0"){#
      ggplot(data_list[[i]], aes(x=anthro, y=depend.var)) +#
        geom_point(alpha = 0.5, color = "grey60") +#
        xlab("Proportion anthropogenic ignitions") +#
        ylab(units_simple[i]) +#
        ggtitle(names_no_units[i]) +#
        scale_y_continuous(trans = "log10")+#
        theme_pubr() +#
        geom_line(aes(y = predict(regression_list[[i]])), lwd=1)#
        	}#
}
par(mfrow=c(2,2))#
for (i in c(4, 8, 3, 14)){#
  plot_segmented(i)#
}
ggarrange(#
  ggplot_segmented(4),#
  ggplot_segmented(8),#
  ggplot_segmented(3),#
  ggplot_segmented(14),#
  nrow=2,#
  ncol = 2#
)
ggplot_segmented<- function(i, let){#
    if (num_breaks[i]=="1"){#
      ggplot(data_list[[i]], aes(x=anthro, y=depend.var)) +#
        geom_point(alpha = 0.5, color = "grey60") +#
        xlab("Proportion anthropogenic ignitions") +#
        ylab(units_simple[i]) +#
        ggtitle(paste0(letters[let], ". ", names_no_units[i]))+#
        scale_y_continuous(trans = "log10")+#
        theme_pubr() +#
        geom_line(aes(y = predict(segmented_list[[i]])), lwd=1)+#
        # geom_segment(aes(x = segmented_list[[i]]$psi[2] - segmented_list[[i]]$psi[3],#
        #              xend = segmented_list[[i]]$psi[2] + segmented_list[[i]]$psi[3],#
        #              y = 1, yend=1),#
        #              color = "blue", lwd = 1.5) +#
        # geom_point(aes(x = segmented_list[[i]]$psi[2],y=1), color = "blue", size = 3)#
        geom_vline(xintercept = segmented_list[[i]]$psi[2], lty =1) +#
        geom_vline(xintercept = segmented_list[[i]]$psi[2]- segmented_list[[i]]$psi[3], lty =2) +#
        geom_vline(xintercept = segmented_list[[i]]$psi[2]+ segmented_list[[i]]$psi[3], lty =2) #
    } else if (num_breaks[i]=="0"){#
      ggplot(data_list[[i]], aes(x=anthro, y=depend.var)) +#
        geom_point(alpha = 0.5, color = "grey60") +#
        xlab("Proportion anthropogenic ignitions") +#
        ylab(units_simple[i]) +#
        ggtitle(names_no_units[i]) +#
        scale_y_continuous(trans = "log10")+#
        theme_pubr() +#
        geom_line(aes(y = predict(regression_list[[i]])), lwd=1)#
        	}#
}
ggarrange(#
  ggplot_segmented(4, 1),#
  ggplot_segmented(8, 2),#
  ggplot_segmented(3, 3),#
  ggplot_segmented(14, 4),#
  nrow=2,#
  ncol = 2#
)
ggarrange(#
  ggplot_segmented(4, 1),#
  ggplot_segmented(8, 2),#
  ggplot_segmented(3, 3),#
  ggplot_segmented(14, 4),#
  nrow=2, ncol = 2#
)
letters[4]
names_no_units
ggplot_segmented<- function(i, let){#
    if (num_breaks[i]=="1"){#
      ggplot(data_list[[i]], aes(x=anthro, y=depend.var)) +#
        geom_point(alpha = 0.5, color = "grey60") +#
        xlab("Proportion anthropogenic ignitions") +#
        ylab(units_simple[i]) +#
        ggtitle(paste0(letters[let], ". ", names_no_units[i]))+#
        scale_y_continuous(trans = "log10")+#
        theme_pubr() +#
        geom_line(aes(y = predict(segmented_list[[i]])), lwd=1)+#
        # geom_segment(aes(x = segmented_list[[i]]$psi[2] - segmented_list[[i]]$psi[3],#
        #              xend = segmented_list[[i]]$psi[2] + segmented_list[[i]]$psi[3],#
        #              y = 1, yend=1),#
        #              color = "blue", lwd = 1.5) +#
        # geom_point(aes(x = segmented_list[[i]]$psi[2],y=1), color = "blue", size = 3)#
        geom_vline(xintercept = segmented_list[[i]]$psi[2], lty =1) +#
        geom_vline(xintercept = segmented_list[[i]]$psi[2]- segmented_list[[i]]$psi[3], lty =2) +#
        geom_vline(xintercept = segmented_list[[i]]$psi[2]+ segmented_list[[i]]$psi[3], lty =2) #
    } else if (num_breaks[i]=="0"){#
      ggplot(data_list[[i]], aes(x=anthro, y=depend.var)) +#
        geom_point(alpha = 0.5, color = "grey60") +#
        xlab("Proportion anthropogenic ignitions") +#
        ylab(units_simple[i]) +#
        ggtitle(paste0(letters[let], ". ", names_no_units[i]))+#
        scale_y_continuous(trans = "log10")+#
        theme_pubr() +#
        geom_line(aes(y = predict(regression_list[[i]])), lwd=1)#
        	}#
}
ggarrange(#
  ggplot_segmented(4, 1),#
  ggplot_segmented(8, 2),#
  ggplot_segmented(3, 3),#
  ggplot_segmented(14, 4),#
  nrow=2, ncol = 2#
)
nrow(samples_df$ign=="Human")
nrow(samples_df[samples_df$ign=="Human",])
nrow(samples_df[samples_df$ign=="Lightning",])
fire_characteristics_ign
mean_char<-vector("list", 15)#
sd_char<-vector("list", 15)#
for (i in 1:15){#
  mean_char[i]<-round(stats::aggregate(samples_ign_mean[,i], by=list(samples_ign_mean$ign), FUN=mean, na.rm=TRUE)[2],1)#
  sd_char[i]<-round(stats::aggregate(samples_ign_mean[,i], by=list(samples_ign_mean$ign), FUN=sd, na.rm=TRUE)[2],1)#
}#
mean_char_df <- data.frame(matrix(unlist(mean_char), nrow=15, byrow=T))#
sd_char_df <- data.frame(matrix(unlist(sd_char), nrow=15, byrow=T))#
fire_char_ign<-cbind(mean_char_df,sd_char_df)#
#
names(fire_char_ign)<-c("Human Ign Mean", "Lightning Ign Mean", "Human Ign Sd", "Lightning Ign Sd")#
fire_characteristics_ign<-fire_char_ign#
fire_characteristics_ign<-data.frame(matrix(NA, nrow = 15, ncol = 3))#
names(fire_characteristics_ign)<-c("Characteristic", "Human Ign", "Lightning Ign")#
for(i in 1:2){#
  fire_characteristics_ign[,i+1]<-paste0(mean_char_df[,i], " (+/-", sd_char_df[,i], ")")#
}#
#
fire_characteristics_ign[,1]<-names(samples_ign_mean[c(1:15)])#
#
# Stats on this#
# compare two unpaired groups - Unpaired t for Gaussian and Mann-Whitney for non-Gaussian#
# (Could use ks.test to see if gaussian (Kolmogorov-Smirnov Test)) - just assume not Gaussian#
sig_char<-vector("numeric", length=15)#
for (i in 1:15){#
  sig_char[i]<-round(wilcox.test(samples_ign_mean[,i]~samples_ign_mean$ign)$p.value, 3)#
}#
fire_characteristics_ign$sig<-ifelse(sig_char<=0.001, "***",#
                                     ifelse(sig_char<=0.01 & sig_char>0.001, "**",#
                                            ifelse(sig_char<=0.05 & sig_char>0.01, "*",-9999)))#
#
### Table S2#
fire_characteristics_ign
samples_ign1<-samples_df[samples_df$anthro>0,]
samples_ign<-samples_ign1[!is.na(samples_ign1$anthro),]
samples_ign_mean<-samples_ign[,c(1:15, 379, 381)]
# Table S2#
mean_char<-vector("list", 15)#
sd_char<-vector("list", 15)#
for (i in 1:15){#
  mean_char[i]<-round(stats::aggregate(samples_ign_mean[,i], by=list(samples_ign_mean$ign), FUN=mean, na.rm=TRUE)[2],1)#
  sd_char[i]<-round(stats::aggregate(samples_ign_mean[,i], by=list(samples_ign_mean$ign), FUN=sd, na.rm=TRUE)[2],1)#
}
mean_char_df <- data.frame(matrix(unlist(mean_char), nrow=15, byrow=T))#
sd_char_df <- data.frame(matrix(unlist(sd_char), nrow=15, byrow=T))#
fire_char_ign<-cbind(mean_char_df,sd_char_df)#
#
names(fire_char_ign)<-c("Human Ign Mean", "Lightning Ign Mean", "Human Ign Sd", "Lightning Ign Sd")#
fire_characteristics_ign<-fire_char_ign#
fire_characteristics_ign<-data.frame(matrix(NA, nrow = 15, ncol = 3))#
names(fire_characteristics_ign)<-c("Characteristic", "Human Ign", "Lightning Ign")#
for(i in 1:2){#
  fire_characteristics_ign[,i+1]<-paste0(mean_char_df[,i], " (+/-", sd_char_df[,i], ")")#
}#
#
fire_characteristics_ign[,1]<-names(samples_ign_mean[c(1:15)])
# Stats on this#
# compare two unpaired groups - Unpaired t for Gaussian and Mann-Whitney for non-Gaussian#
# (Could use ks.test to see if gaussian (Kolmogorov-Smirnov Test)) - just assume not Gaussian#
sig_char<-vector("numeric", length=15)#
for (i in 1:15){#
  sig_char[i]<-round(wilcox.test(samples_ign_mean[,i]~samples_ign_mean$ign)$p.value, 3)#
}#
fire_characteristics_ign$sig<-ifelse(sig_char<=0.001, "***",#
                                     ifelse(sig_char<=0.01 & sig_char>0.001, "**",#
                                            ifelse(sig_char<=0.05 & sig_char>0.01, "*",-9999)))#
#
### Table S2#
fire_characteristics_ign
round(wilcox.test(samples_ign_mean[,1]~samples_ign_mean$ign)$p.value
)
wilcox.test(samples_ign_mean[,1]~samples_ign_mean$ign)$p.value
wilcox.test(samples_ign_mean[,2]~samples_ign_mean$ign)$p.value
wilcox.test(samples_ign_mean[,3]~samples_ign_mean$ign)$p.value
wilcox.test(samples_ign_mean[,4]~samples_ign_mean$ign)$p.value
wilcox.test(samples_ign_mean[,5]~samples_ign_mean$ign)$p.value
wilcox.test(samples_ign_mean[,6]~samples_ign_mean$ign)$p.value
wilcox.test(samples_ign_mean[,7]~samples_ign_mean$ign)$p.value
wilcox.test(samples_ign_mean[,8]~samples_ign_mean$ign)$p.value
wilcox.test(samples_ign_mean[,9]~samples_ign_mean$ign)$p.value
wilcox.test(samples_ign_mean[,10]~samples_ign_mean$ign)$p.value
wilcox.test(samples_ign_mean[,11]~samples_ign_mean$ign)$p.value
wilcox.test(samples_ign_mean[,12]~samples_ign_mean$ign)$p.value
wilcox.test(samples_ign_mean[,13]~samples_ign_mean$ign)$p.value
wilcox.test(samples_ign_mean[,14]~samples_ign_mean$ign)$p.value
wilcox.test(samples_ign_mean[,15]~samples_ign_mean$ign)$p.value
wilcox.test(samples_ign_mean[,16]~samples_ign_mean$ign)$p.value
wilcox.test(samples_ign_mean[,15]~samples_ign_mean$ign)
wilcox.test(samples_ign_mean[,1]~samples_ign_mean$ign)
fire_characteristics_ign
slopes1
fire_chars
slope_stuff
# For fires started by people vs lightning#
# Function to compute mean annual (time) values of a fire characteristic (title) by ign type (ign)#
mean_annual_value_by_group<-function(title){#
  value_by_group<-title %>% #
    group_by(ign, time) %>% #
    summarise(#
      count = n(),#
      value_by_group = mean(value, na.rm = TRUE)#
    )#
  value_by_group#
}#
#
# pass this list to function above#
grouped_list=vector("list", 15)#
for (i in 1:15){#
  grouped_list[[i]]<-mean_annual_value_by_group(fire_chars[[i]])#
}
names(grouped_list)<-names_vector#
#
#fix the years#
for(i in c(1,4, 5, 13)){#
  grouped_list[[i]]$year<-grouped_list[[i]]$time+2003#
}#
#
for(i in c(2, 6, 7, 10, 12)){#
  grouped_list[[i]]$year<-grouped_list[[i]]$time+1984#
}#
#
for(i in c(3, 8, 9, 11, 14, 15)){#
  grouped_list[[i]]$year<-grouped_list[[i]]$time+1992#
}#
# Fit linear model for each#
library(nlme)#
lm_summary_list<-vector("list", 15)#
for (i in 1:15){#
  lm_summary_list[[i]]<-summary(lmList(value ~ time | ign, data=fire_chars[[i]], na.action=na.omit))#
}#
#
# Slopes of ign groups#
slopes<-data.frame(matrix(NA, nrow = 15, ncol = 3))#
slopes[,1]<-names_vector#
#
# pull out slopes and sig of slopes#
for (i in 1:15){#
  slopes[i, 2]<-paste0(round(lm_summary_list[[i]]$coefficients[14], 2), " (+/-", round(lm_summary_list[[i]]$coefficients[17], 2), ")", #
                       ifelse(lm_summary_list[[i]]$coefficients[23]>0.1, " ",#
                              ifelse(lm_summary_list[[i]]$coefficients[23]>0.05 & lm_summary_list[[i]]$coefficients[23]<=0.1, "*",#
                                     ifelse(lm_summary_list[[i]]$coefficients[23]>0.01 & lm_summary_list[[i]]$coefficients[23]<=0.05, "**",#
                                            ifelse(lm_summary_list[[i]]$coefficients[23]<=0.01, "***", NA)))))#
  slopes[i, 3]<-paste0(round(lm_summary_list[[i]]$coefficients[15], 2), " (+/-", round(lm_summary_list[[i]]$coefficients[18], 2), ")", #
                       ifelse(lm_summary_list[[i]]$coefficients[24]>0.1, " ",#
                              ifelse(lm_summary_list[[i]]$coefficients[24]>0.05 & lm_summary_list[[i]]$coefficients[24]<=0.1, "*",#
                                     ifelse(lm_summary_list[[i]]$coefficients[24]>0.01 & lm_summary_list[[i]]$coefficients[24]<=0.05, "**",#
                                            ifelse(lm_summary_list[[i]]$coefficients[24]<=0.01, "***", NA)))))#
}#
#
slopes_diff<-data.frame(matrix(NA, nrow = 15, ncol = 2))#
slopes_diff[,1]<-names_vector#
names(slopes_diff)<-c("Fire characteristic", "Greater")#
#
for (i in 1:15){#
  slopes_diff[i, 2]<-ifelse(#
    (lm_summary_list[[i]]$coefficients[14] > lm_summary_list[[i]]$coefficients[15] & #
       lm_summary_list[[i]]$coefficients[14] > (lm_summary_list[[i]]$coefficients[15] + lm_summary_list[[i]]$coefficients[18])), "Human", #
    ifelse(#
      (lm_summary_list[[i]]$coefficients[15] > lm_summary_list[[i]]$coefficients[14] & #
         lm_summary_list[[i]]$coefficients[15] > (lm_summary_list[[i]]$coefficients[14] + lm_summary_list[[i]]$coefficients[17])), "Lightning", #
      "Neither"))#
}
slope_stuff<-cbind(slopes, slopes_diff)
slope_stuff<-slope_stuff[,c(-4)]
# Percent change for each over time period#
# Anthro ignitions#
initial<-vector("list", 15)#
final<-vector("list", 15)#
change<-vector("list", 15)#
perc_change<-vector("list", 15)#
#
for (c in 1:15){#
  for (i in 2:3){#
    initial[[c]][i]<-(summary(lmList(value ~ time | ign, data=fire_chars[[c]], na.action=na.omit))$coefficients[i])#
    final[[c]][i]<-(stats::predict.lm(lmList(value ~ time | ign, data=fire_chars[[c]], na.action=na.omit)[[i]], newdata=data.frame(time=(max(fire_chars[[c]]$time)-min(fire_chars[[c]]$time)))))#
    change[[c]][i]<-final[[c]][i]-initial[[c]][i]#
    perc_change[[c]][i]<-(change[[c]][i]/initial[[c]][i])*100#
  }#
}#
#
names(perc_change)<-names_vector#
#
perc_change_human<-vector("numeric", length=15)#
perc_change_lightning<-vector("numeric", length=15)#
for (i in 1:15){#
  perc_change_human[i]<-perc_change[[i]][2]#
  perc_change_lightning[i]<-perc_change[[i]][3]#
}#
#
slope_stuff$perc_change_human<-round(perc_change_human,2)#
slope_stuff$perc_change_lightning<-round(perc_change_lightning,2)#
#
### Table S3#
slope_stuff
summary(samples_df_mean$Perc_human_Short_mean)[2]#
samples_df_mean$anthro_group4<-#
  ifelse(samples_df_mean$Perc_human_Short_mean<=samples_df_mean$Perc_human_Short_mean[2], 1, #
         ifelse(samples_df_mean$Perc_human_Short_mean<=samples_df_mean$Perc_human_Short_mean[3] & samples_df_mean$Perc_human_Short_mean>samples_df$Perc_human_Short_mean[2], 2, #
                ifelse(samples_df_mean$Perc_human_Short_mean<=samples_df_mean$Perc_human_Short_mean[5] & samples_df_mean$Perc_human_Short_mean>samples_df$Perc_human_Short_mean[3], 3,#
                       ifelse(samples_df_mean$Perc_human_Short_mean>samples_df_mean$Perc_human_Short_mean[5], 4, -9999#
                       ))))#
#
samples_df_mean$anthro_group3<-#
  ifelse(samples_df_mean$Perc_human_Short_mean<=0.25, 1, #
         ifelse(samples_df_mean$Perc_human_Short_mean<0.75 & samples_df_mean$Perc_human_Short_mean>0.25, 2, #
                ifelse(samples_df_mean$Perc_human_Short_mean>=0.75, 3, -9999#
                )))#
#
samples_ign_mean$anthro_group3<-#
  ifelse(samples_ign_mean$Perc_human_Short_mean<=0.25, 1, #
         ifelse(samples_ign_mean$Perc_human_Short_mean<0.75 & samples_ign_mean$Perc_human_Short_mean>0.25, 2, #
                ifelse(samples_ign_mean$Perc_human_Short_mean>=0.75, 3, -9999#
                )))
samples_df_mean$Mean_FRP_MODIS_mean.z<-scale(samples_df_mean$Mean_FRP_MODIS_mean)
samples_df_mean$Std_JD_Short_mean.z<-scale(samples_df_mean$Std_JD_Short_mean)#
samples_df_mean$Number_fires_Short_mean.z<-scale(samples_df_mean$Number_fires_Short_mean)#
samples_df_mean$Perc_human_Short_mean.z<-scale(samples_df_mean$Perc_human_Short_mean)#
samples_df_mean$Mean_area_Short_mean.z<-scale(samples_df_mean$Mean_area_Short_mean)#
samples_df_mean$anthro_group3<-as.factor(samples_df_mean$anthro_group3)#
#
# model size as a function of season length, frequency, and anthro ign#
size1 <- lm(Mean_area_Short_mean.z ~ Std_JD_Short_mean.z + Number_fires_Short_mean.z + Perc_human_Short_mean.z, samples_df_mean)#
summary(size1)
intensity1 <- lm(Mean_FRP_MODIS_mean.z ~ Std_JD_Short_mean.z + Number_fires_Short_mean.z + Perc_human_Short_mean.z, samples_df_mean)#
summary(intensity1)
relImp_size<-calc.relimp(size1, type="lmg", rela=TRUE)
ibrary(relaimpo)#
relImp_size<-calc.relimp(size1, type="lmg", rela=TRUE)#
sort(relImp_size$lmg, decreasing=TRUE)
library(relaimpo)
relImp_size<-calc.relimp(size1, type="lmg", rela=TRUE)#
sort(relImp_size$lmg, decreasing=TRUE)
relImp_intensity<-calc.relimp(intensity1, type="lmg", rela=TRUE)#
sort(relImp_intensity$lmg, decreasing=TRUE)
relImp_size
ggarrange(p1,p2, ncol=2, nrow=1, legend=c("right"), common.legend=TRUE)
ggarrange(make_nich_fig(2, 1,1), make_nich_fig2(4, 3,2),
ncol=2, nrow=1, legend=c("right"), common.legend=TRUE)
ggarrange(make_nich_fig(8, 4,1), make_nich_fig2(20, 19,2),#
          ncol=2, nrow=1, legend=c("right"), common.legend=TRUE)
means_sds <- samples_ign_mean %>%#
  group_by(ign) %>%#
  summarise(mean_frp = median(log(Mean_FRP_MODIS_mean), na.rm=T),#
            sd_frp = sd(log(Mean_FRP_MODIS_mean), na.rm = T),#
            mean_area = median(log(Mean_area_Short_mean)),#
            sd_area = sd(log(Mean_area_Short_mean)),#
            mean_jd = median(log(Std_JD_Short_mean2), na.rm=T),#
            sd_jd = sd(log(Std_JD_Short_mean2), na.rm = T),#
            mean_n = median(log(Number_fires_Short_mean2), na.rm=T),#
            sd_n = sd(log(Number_fires_Short_mean2), na.rm = T)) %>%#
  ungroup %>%#
  mutate(lowerf = mean_frp - sd_frp,#
         upperf = mean_frp + sd_frp,#
         lowera = mean_area - sd_area,#
         uppera = mean_area + sd_area,#
         lowerj = mean_jd - sd_jd,#
         upperj = mean_jd + sd_jd,#
         lowern = mean_n - sd_n,#
         uppern = mean_n + sd_n)#
#
library(scales)#
p1 <- ggplot(samples_ign_mean, aes(x=(Mean_area_Short_mean), #
                                   y=(Mean_FRP_MODIS_mean),#
                                   color = ign)) +#
  geom_point(alpha = 0.4, size = 1) +#
  geom_errorbar(data = means_sds, width=0, #alpha = .2,#
                aes(x = exp(mean_area),#
                    ymin = exp(mean_frp - sd_frp),#
                    ymax = exp(mean_frp + sd_frp)),#
                inherit.aes = FALSE) +#
  geom_errorbarh(data = means_sds, height=0, #alpha = .2,#
                 aes(y = exp(mean_frp),#
                     xmin = exp(lowera),#
                     xmax = exp(mean_area + sd_area)),#
                 inherit.aes = FALSE)+#
  geom_point(data=means_sds, alpha = .2, size=1.5, aes(x=exp(mean_area), y=exp(mean_frp)), inherit.aes = FALSE) +#
  ggtitle("a.")      +#
  scale_y_continuous(trans = "log10") +#
  scale_x_log10(breaks = trans_breaks("log10", function(x) 10^x),#
                labels = trans_format("log10", math_format(10^.x))) + #
  scale_color_manual(values = c("#E69F00", "#56B4E9"),name = "Ignition Source")+#
  ylab("Average Intensity (MW)") +#
  xlab("Average Fire Size (ha)") +#
  #annotation_logticks()  +#
  theme_pubr();p1#
p2 <- ggplot(samples_ign_mean, aes(x=Number_fires_Short_mean2, #
                                   y=Std_JD_Short_mean2,#
                                   color = ign)) +#
  geom_point(alpha = 0.4, size = 1) +#
  geom_errorbar(data = means_sds, width=0, #alpha = .2,#
                aes(x = exp(mean_n),#
                    ymin = exp(mean_jd - sd_jd),#
                    ymax = exp(mean_jd + sd_jd)),#
                inherit.aes = FALSE) +#
  geom_errorbarh(data = means_sds, height=0, #alpha = .2,#
                 aes(y = exp(mean_jd),#
                     xmin = exp(lowern),#
                     xmax = exp(mean_n + sd_n)),#
                 inherit.aes = FALSE)+#
  ggtitle("b.")              + #
  geom_point(data=means_sds, alpha = .2, size=1.5, aes(x=exp(mean_n), y=exp(mean_jd)), inherit.aes = FALSE) +#
  scale_y_continuous(trans = "log10") +#
  scale_x_log10(breaks = trans_breaks("log10", function(x) 10^x),#
                labels = trans_format("log10", math_format(10^.x))) +   scale_color_manual(values = c("#E69F00", "#56B4E9"),name = "Ignition Source")+#
  xlab("Fire frequency (n fires)") +#
  ylab("Season Length (days)") +#
  #annotation_logticks()  +#
  theme_pubr();p2#
#
ggarrange(p1,p2, ncol=2, nrow=1, legend=c("right"), common.legend=TRUE)
names(samples_df_mean)
summary(samples_df_mean$Perc_human_Short_mean)[2]#
samples_df_mean$anthro_group4<-#
  ifelse(samples_df_mean$Perc_human_Short_mean<=samples_df_mean$Perc_human_Short_mean[2], 1, #
         ifelse(samples_df_mean$Perc_human_Short_mean<=samples_df_mean$Perc_human_Short_mean[3] & samples_df_mean$Perc_human_Short_mean>samples_df$Perc_human_Short_mean[2], 2, #
                ifelse(samples_df_mean$Perc_human_Short_mean<=samples_df_mean$Perc_human_Short_mean[5] & samples_df_mean$Perc_human_Short_mean>samples_df$Perc_human_Short_mean[3], 3,#
                       ifelse(samples_df_mean$Perc_human_Short_mean>samples_df_mean$Perc_human_Short_mean[5], 4, -9999#
                       ))))#
#
samples_df_mean$anthro_group3<-#
  ifelse(samples_df_mean$Perc_human_Short_mean<=0.25, 1, #
         ifelse(samples_df_mean$Perc_human_Short_mean<0.75 & samples_df_mean$Perc_human_Short_mean>0.25, 2, #
                ifelse(samples_df_mean$Perc_human_Short_mean>=0.75, 3, -9999#
                )))#
#
samples_ign_mean$anthro_group3<-#
  ifelse(samples_ign_mean$Perc_human_Short_mean<=0.25, 1, #
         ifelse(samples_ign_mean$Perc_human_Short_mean<0.75 & samples_ign_mean$Perc_human_Short_mean>0.25, 2, #
                ifelse(samples_ign_mean$Perc_human_Short_mean>=0.75, 3, -9999#
                )))
make_nich_fig<-function(variable1, variable2, let){#
  gg1 <- merge(samples_ign_mean, aggregate(cbind(mean.x=log(samples_ign_mean[,variable1]), mean.y=log(samples_ign_mean[,variable2]))~anthro_group3, samples_ign_mean, mean, na.action=na.omit), by="anthro_group3")#
  gg <- merge(gg1, aggregate(cbind(se.x=log(samples_ign_mean[,variable1]), se.y=log(samples_ign_mean[,variable2]))~anthro_group3, samples_ign_mean, sd, na.action=na.omit), by="anthro_group3")#
  ggplot(gg, aes(log(gg[,variable1+1]), log(gg[,variable2+1]),color=factor(anthro_group3)))+#
    geom_point(alpha=.4, size=1)+#
    ggtitle(paste0(letters[let], ". "))+#
    labs(x=paste0("log ", names_simple[variable1]), y=paste0("log ", names_simple[variable2]), color="Ignition Source")+ #
    scale_colour_manual(values=(cbPalette[c(2,1)]), labels=c("Primarily Lightning (>75%)", "Primarily Anthropogenic (>75%)")) +#
    geom_point(data=gg, alpha = .2, size=1.5, aes(x=mean.x, y=mean.y), inherit.aes = FALSE)+#
    geom_errorbar(data=gg, width=0, alpha = .2, aes(x=mean.x, ymin=mean.y-se.y,ymax=mean.y+se.y), inherit.aes = FALSE)+#
    geom_errorbarh(data=gg, height=0, alpha = .2,  aes(y=mean.y, xmin=mean.x-se.x,xmax=mean.x+se.x), inherit.aes = FALSE)#
}	#
samples_ign_mean$Std_JD_Short_mean2<-ifelse(samples_ign_mean$Std_JD_Short_mean==0, NA, samples_ign_mean$Std_JD_Short_mean)#
samples_ign_mean$Number_fires_Short_mean2<-ifelse(samples_ign_mean$Number_fires_Short_mean==0, NA, samples_ign_mean$Number_fires_Short_mean)#
#
names(samples_ign_mean)#
#
make_nich_fig2<-function(variable1, variable2, let){#
  gg1 <- merge(samples_ign_mean, aggregate(cbind(mean.x=log(samples_ign_mean[,variable1]), mean.y=log(samples_ign_mean[,variable2]))~anthro_group3, samples_ign_mean, mean, na.action=na.omit), by="anthro_group3")#
  gg <- merge(gg1, aggregate(cbind(se.x=log(samples_ign_mean[,variable1]), se.y=log(samples_ign_mean[,variable2]))~anthro_group3, samples_ign_mean, sd, na.action=na.omit), by="anthro_group3")#
  ggplot(gg, aes(log(gg[,variable1]), log(gg[,variable2]),color=factor(anthro_group3)))+#
    geom_point(alpha=.2, size=1)+#
    ggtitle(paste0(letters[let], ". "))+#
    labs(x=paste0("log ", names_simple[3]), y=paste0("log ", names_simple[14]), color="Ignition Source")+ #
    scale_colour_manual(values=(cbPalette[c(2,1)]), labels=c("Primarily Lightning (>75%)", "Primarily Anthropogenic (>75%)")) +#
    geom_point(data=gg, alpha = .2, size=1.5, aes(x=mean.x, y=mean.y), inherit.aes = FALSE)+#
    geom_errorbar(data=gg, width=0, alpha = .2, aes(x=mean.x, ymin=mean.y-se.y,ymax=mean.y+se.y), inherit.aes = FALSE)+#
    geom_errorbarh(data=gg, height=0, alpha = .2, aes(y=mean.y, xmin=mean.x-se.x,xmax=mean.x+se.x),  inherit.aes = FALSE)#
}
ggarrange(make_nich_fig(8, 4,1), make_nich_fig2(20, 19,2),#
          ncol=2, nrow=1, legend=c("right"), common.legend=TRUE)
means_sds <- samples_ign_mean %>%#
  group_by(ign) %>%#
  summarise(mean_frp = median(log(Mean_FRP_MODIS_mean), na.rm=T),#
            sd_frp = sd(log(Mean_FRP_MODIS_mean), na.rm = T),#
            mean_area = median(log(Mean_area_Short_mean)),#
            sd_area = sd(log(Mean_area_Short_mean)),#
            mean_jd = median(log(Std_JD_Short_mean2), na.rm=T),#
            sd_jd = sd(log(Std_JD_Short_mean2), na.rm = T),#
            mean_n = median(log(Number_fires_Short_mean2), na.rm=T),#
            sd_n = sd(log(Number_fires_Short_mean2), na.rm = T)) %>%#
  ungroup %>%#
  mutate(lowerf = mean_frp - sd_frp,#
         upperf = mean_frp + sd_frp,#
         lowera = mean_area - sd_area,#
         uppera = mean_area + sd_area,#
         lowerj = mean_jd - sd_jd,#
         upperj = mean_jd + sd_jd,#
         lowern = mean_n - sd_n,#
         uppern = mean_n + sd_n)#
#
library(scales)#
p1 <- ggplot(samples_ign_mean, aes(x=(Mean_area_Short_mean), #
                                   y=(Mean_FRP_MODIS_mean),#
                                   color = ign)) +#
  geom_point(alpha = 0.4, size = 1) +#
  geom_errorbar(data = means_sds, width=0, #alpha = .2,#
                aes(x = exp(mean_area),#
                    ymin = exp(mean_frp - sd_frp),#
                    ymax = exp(mean_frp + sd_frp)),#
                inherit.aes = FALSE) +#
  geom_errorbarh(data = means_sds, height=0, #alpha = .2,#
                 aes(y = exp(mean_frp),#
                     xmin = exp(lowera),#
                     xmax = exp(mean_area + sd_area)),#
                 inherit.aes = FALSE)+#
  geom_point(data=means_sds, alpha = .2, size=1.5, aes(x=exp(mean_area), y=exp(mean_frp)), inherit.aes = FALSE) +#
  ggtitle("a.")      +#
  scale_y_continuous(trans = "log10") +#
  scale_x_log10(breaks = trans_breaks("log10", function(x) 10^x),#
                labels = trans_format("log10", math_format(10^.x))) + #
  scale_color_manual(values = c("#E69F00", "#56B4E9"),name = "Ignition Source")+#
  ylab("Average Intensity (MW)") +#
  xlab("Average Fire Size (ha)") +#
  #annotation_logticks()  +#
  theme_pubr();p1#
p2 <- ggplot(samples_ign_mean, aes(x=Number_fires_Short_mean2, #
                                   y=Std_JD_Short_mean2,#
                                   color = ign)) +#
  geom_point(alpha = 0.4, size = 1) +#
  geom_errorbar(data = means_sds, width=0, #alpha = .2,#
                aes(x = exp(mean_n),#
                    ymin = exp(mean_jd - sd_jd),#
                    ymax = exp(mean_jd + sd_jd)),#
                inherit.aes = FALSE) +#
  geom_errorbarh(data = means_sds, height=0, #alpha = .2,#
                 aes(y = exp(mean_jd),#
                     xmin = exp(lowern),#
                     xmax = exp(mean_n + sd_n)),#
                 inherit.aes = FALSE)+#
  ggtitle("b.")              + #
  geom_point(data=means_sds, alpha = .2, size=1.5, aes(x=exp(mean_n), y=exp(mean_jd)), inherit.aes = FALSE) +#
  scale_y_continuous(trans = "log10") +#
  scale_x_log10(breaks = trans_breaks("log10", function(x) 10^x),#
                labels = trans_format("log10", math_format(10^.x))) +   scale_color_manual(values = c("#E69F00", "#56B4E9"),name = "Ignition Source")+#
  xlab("Fire frequency (n fires)") +#
  ylab("Season Length (days)") +#
  #annotation_logticks()  +#
  theme_pubr();p2
ggarrange(p1,p2, ncol=2, nrow=1, legend=c("right"), common.legend=TRUE)
